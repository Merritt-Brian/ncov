{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SciServer import Jobs,Authentication,Config\n",
    "import json\n",
    "import requests\n",
    "import ipywidgets as widgets\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathForUserVolume(uv):\n",
    "    return '{0}/{1}/{2}'.format(uv['rootVolumeName'],uv['owner'],uv['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code replaces similar function in SciServer.Jobs\n",
    "# That verison does not yet support writing to a data volume\n",
    "def submitShellCommandJob(shellCommand, dockerComputeDomain = None, dockerImageName = None, userVolumes = None, dataVolumes = None, resultsFolderPath = \"\", jobAlias = \"\"):\n",
    "    \"\"\"\n",
    "    Submits a shell command for execution (as an asynchronous job) inside a Docker compute domain.\n",
    "    :param shellCommand: shell command (string) defined by the user.\n",
    "    :param dockerComputeDomain: object (dictionary) that defines a Docker compute domain. A list of these kind of objects available to the user is returned by the function Jobs.getDockerComputeDomains().\n",
    "    :param dockerImageName: name (string) of the Docker image for executing the notebook. E.g.,  dockerImageName=\"Python (astro)\". An array of available Docker images is defined as the 'images' property in the dockerComputeDomain object.\n",
    "    :param userVolumes: a list with the names of user volumes (with optional write permissions) that will be mounted to the docker Image.\n",
    "           E.g., userVolumes = [{'name':'persistent', 'needsWriteAccess':False},{'name':'scratch', , 'needsWriteAccess':True}]\n",
    "           A list of available user volumes can be found as the 'userVolumes' property in the dockerComputeDomain object. If userVolumes=None, then all available user volumes are mounted, with 'needsWriteAccess' = True if the user has Write permissions on the volume.\n",
    "    :param dataVolumes: a list with the names of data volumes that will be mounted to the docker Image.\n",
    "           E.g., dataVolumes=[{\"name\":\"SDSS_DAS\"}, {\"name\":\"Recount\"}].\n",
    "           A list of available data volumes can be found as the 'volumes' property in the dockerComputeDomain object. If dataVolumes=None, then all available data volumes are mounted.\n",
    "    :param resultsFolderPath: full path to results folder (string) where the shell command is executed. E.g.: /home/idies/workspace/rootVolume/username/userVolume/jobsFolder. If not set, then a default folder will be set automatically.\n",
    "    :param jobAlias: alias (string) of job, defined by the user.\n",
    "    :return: the job ID (int)\n",
    "    :raises: Throws an exception if the HTTP request to the Authentication URL returns an error. Throws an exception if the HTTP request to the JOBM API returns an error, or if the volumes defined by the user are not available in the Docker compute domain.\n",
    "    :example: dockerComputeDomain = Jobs.getDockerComputeDomains()[0]; job = Jobs.submitShellCommandJob('pwd', dockerComputeDomain, 'Python (astro)', [{'name':'persistent'},{'name':'scratch', 'needsWriteAccess':True}], [{'name':'SDSS_DAS'}], 'myNewJob')\n",
    "    .. seealso:: Jobs.submitNotebookJob, Jobs.getJobStatus, Jobs.getDockerComputeDomains, Jobs.cancelJob\n",
    "    \"\"\"\n",
    "\n",
    "    token = Authentication.login(UserName=USERNAME, Password=PASSWORD)\n",
    "    if token is not None and token != \"\":\n",
    "\n",
    "        if Config.isSciServerComputeEnvironment():\n",
    "            taskName = \"Compute.SciScript-Python.Jobs.submitShellCommandJob\"\n",
    "        else:\n",
    "            taskName = \"SciScript-Python.Jobs.submitShellCommandJob\"\n",
    "\n",
    "        if dockerComputeDomain is None:\n",
    "            dockerComputeDomains = getDockerComputeDomains();\n",
    "            if dockerComputeDomains .__len__() > 0:\n",
    "                dockerComputeDomain = dockerComputeDomains[0];\n",
    "            else:\n",
    "                raise Exception(\"There are no dockerComputeDomains available for the user.\");\n",
    "\n",
    "        if dockerImageName is None:\n",
    "            images = dockerComputeDomain.get('images');\n",
    "            if images.__len__() > 0:\n",
    "                dockerImageName = images[0].get('name')\n",
    "            else:\n",
    "                raise Exception(\"dockerComputeDomain has no docker images available for the user.\");\n",
    "\n",
    "        uVols = [];\n",
    "        for uVol in userVolumes:\n",
    "            found = False;\n",
    "            for vol in dockerComputeDomain.get('userVolumes'):\n",
    "                if vol.get('name') == uVol.get('name'):\n",
    "                    found = True;\n",
    "                    if (uVol.get('needsWriteAccess')):\n",
    "                        if uVol.get('needsWriteAccess') == True and 'write' in vol.get('allowedActions'):\n",
    "                            uVols.append({'userVolumeId': vol.get('id'), 'needsWriteAccess': True});\n",
    "                        else:\n",
    "                            uVols.append({'userVolumeId': vol.get('id'), 'needsWriteAccess': False});\n",
    "                    else:\n",
    "                        if 'write' in vol.get('allowedActions'):\n",
    "                            uVols.append({'userVolumeId': vol.get('id'), 'needsWriteAccess': True});\n",
    "                        else:\n",
    "                            uVols.append({'userVolumeId': vol.get('id'), 'needsWriteAccess': False});\n",
    "\n",
    "            if not found:\n",
    "                raise Exception(\"User volume '\" + uVol.get('name') + \"' not found within Compute domain\")\n",
    "\n",
    "        datVols = [];\n",
    "        for dVol in dataVolumes:\n",
    "            found = False;\n",
    "            for vol in dockerComputeDomain.get('volumes'):\n",
    "                name=dVol.get('name')\n",
    "                if name == vol.get('name'):\n",
    "                    found = True\n",
    "                    if (vol.get('needsWriteAccess')):\n",
    "                        if vol.get('needsWriteAccess') == True and vol.get('writable') == True:\n",
    "                            datVols.append({'name': name, 'writable': True});\n",
    "                        else:\n",
    "                            datVols.append({'name': name, 'writable': False});\n",
    "                    else:\n",
    "                        if vol.get('writable'):\n",
    "                            datVols.append({'name': name, 'writable': True});\n",
    "                        else:\n",
    "                            datVols.append({'name': name, 'writable': False});\n",
    "                    found = True;\n",
    "\n",
    "            if not found:\n",
    "                raise Exception(\"Data volume '\" + dVol.get('name') + \"' not found within Compute domain\")\n",
    "\n",
    "\n",
    "        dockerComputeEndpoint = dockerComputeDomain.get('apiEndpoint');\n",
    "\n",
    "        dockerJobModel = {\n",
    "            \"command\": shellCommand,\n",
    "            \"submitterDID\": jobAlias,\n",
    "            \"dockerComputeEndpoint\": dockerComputeEndpoint,\n",
    "            \"dockerImageName\": dockerImageName,\n",
    "            \"volumeContainers\": datVols,\n",
    "            \"userVolumes\": uVols,\n",
    "            \"resultsFolderURI\": resultsFolderPath\n",
    "        }\n",
    "        data = json.dumps(dockerJobModel).encode()\n",
    "        url = Config.RacmApiURL + \"/jobm/rest/jobs/docker?TaskName=\"+taskName;\n",
    "        headers = {'X-Auth-Token': token, \"Content-Type\": \"application/json\"}\n",
    "        res = requests.post(url, data=data, headers=headers, stream=True)\n",
    "\n",
    "        if res.status_code != 200:\n",
    "            raise Exception(\"Error when submitting a job to the JOBM API.\\nHttp Response from JOBM API returned status code \" + str(res.status_code) + \":\\n\" + res.content.decode());\n",
    "        else:\n",
    "            return (json.loads(res.content.decode())).get('id')\n",
    "    else:\n",
    "        raise Exception(\"User token is not defined. First log into SciServer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sciserver User Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your sciserver username and password\n",
    "USERNAME='ernluaw1'\n",
    "PASSWORD='-------'\n",
    "\n",
    "# define the required job environment\n",
    "DOMAIN='COVID-19 Jobs'  # change with name of new compute domain\n",
    "IMAGE='SciServer Essentials'\n",
    "\n",
    "# define lists of user and data volumes that should be mounted\n",
    "# Add those that you \n",
    "USERVOLUMES=['Storage/ernluaw1/persistent','Temporary/ernluaw1/scratch']\n",
    "DATAVOLUMES=['COVID-19']\n",
    "\n",
    "RESULTSFOLDERPATH = \"/home/idies/workspace/Temporary/ernluaw1/scratch/jobs\"\n",
    "JOBALIAS = \"nanopolish-medaka\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains=Jobs.getDockerComputeDomains()\n",
    "domain=None\n",
    "image=None\n",
    "volumes=[]\n",
    "userVolumes=[]\n",
    "dataVolumes=[]\n",
    "for d in domains:\n",
    "    if d['name'] == DOMAIN:\n",
    "        domain=d\n",
    "        for im in d['images']:\n",
    "            if im['name'] == IMAGE:\n",
    "                image = im\n",
    "        for v in d['volumes']:\n",
    "            if v['name'] in DATAVOLUMES:\n",
    "                dataVolumes.append({\"name\":v['name'],'needsWriteAccess':True})\n",
    "        for uv in d['userVolumes']:\n",
    "            path=pathForUserVolume(uv)\n",
    "            if path in USERVOLUMES:\n",
    "                userVolumes.append({'name':uv['name'],'rootVolumeName':uv['rootVolumeName']\n",
    "                                    ,'owner':uv['owner'],'needsWriteAccess':True})\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4: Draft Consensus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nanopolish script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_nanopolish='bash -x /home/idies/workspace/covid19/code/ncov/pipeline_scripts/artic-consensus-nanopolish.sh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medaka script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_medaka = 'bash -x /home/idies/workspace/covid19/code/ncov/pipeline_scripts/artic-module4-draft-consensus-medaka.sh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequencing run directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir='/home/idies/workspace/Temporary/ernluaw1/scratch/test_modules'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find samples for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_4_get_files(run_dir):\n",
    "    input_dir= run_dir + '/artic-pipeline/3-normalization'\n",
    "    sample_dirs=[d[0] for d in walk(input_dir)]\n",
    "\n",
    "    files=[]\n",
    "\n",
    "    for sample_dir in sample_dirs:\n",
    "        for file in listdir(sample_dir):\n",
    "            if file.endswith(\".fq\"):\n",
    "                files.append(join(sample_dir,file))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_4_input_files=module_4_get_files(run_dir)\n",
    "if len(module_4_input_files)==0:\n",
    "    print(\"Input Fastq files for Module 4 not found!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/idies/workspace/Temporary/ernluaw1/scratch/test_modules/artic-pipeline/3-normalization/MDHP-00115_NB01/MDHP-00115_NB01.covfiltered.fq',\n",
       " '/home/idies/workspace/Temporary/ernluaw1/scratch/test_modules/artic-pipeline/3-normalization/MDHP-00116_NB02/MDHP-00116_NB02.covfiltered.fq']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_4_input_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create command: merge bash script with parameters and input files for analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands=[]\n",
    "for i in range(len(module_4_input_files)):\n",
    "    module_4_job_no=i\n",
    "    command = script_nanopolish + \" \" + module_4_input_files[i] + \";\" + \\\n",
    "        script_medaka + \" \" + module_4_input_files[i] + \" \" + str(module_4_job_no)\n",
    "    commands.append(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bash /home/idies/workspace/covid19/code/ncov/pipeline_scripts/artic-consensus-nanopolish.sh /home/idies/workspace/Temporary/ernluaw1/scratch/test_modules/artic-pipeline/3-normalization/MDHP-00115_NB01/MDHP-00115_NB01.covfiltered.fq;bash /home/idies/workspace/covid19/code/ncov/pipeline_scripts/artic-module4-draft-consensus-medaka.sh /home/idies/workspace/Temporary/ernluaw1/scratch/test_modules/artic-pipeline/3-normalization/MDHP-00115_NB01/MDHP-00115_NB01.covfiltered.fq 0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_batch(commands):\n",
    "    jobs=[]\n",
    "    for command in commands:\n",
    "        job=submitShellCommandJob(shellCommand=command\n",
    "                                    , dockerComputeDomain = domain\n",
    "                                    , dockerImageName = IMAGE\n",
    "                                    , userVolumes = userVolumes, dataVolumes=dataVolumes\n",
    "                                    , resultsFolderPath = RESULTSFOLDERPATH\n",
    "                                    , jobAlias = JOBALIAS)\n",
    "        jobs.append(job)\n",
    "        time.sleep(30)\n",
    "    return jobs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=submit_batch(commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
