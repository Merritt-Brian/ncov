{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submit a shell command as a batch job.\n",
    "See https://github.com/sciserver/SciScript-Python/blob/Feature_Jobs/py3/SciServer/Jobs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SciServer import Jobs,Authentication,Config\n",
    "import json\n",
    "import requests\n",
    "import ipywidgets as widgets\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, isdir, join\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathForUserVolume(uv):\n",
    "    return '{0}/{1}/{2}'.format(uv['rootVolumeName'],uv['owner'],uv['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code replaces similar function in SciServer.Jobs\n",
    "# That verison does not yet support writing to a data volume\n",
    "def submitShellCommandJob(shellCommand, dockerComputeDomain = None, dockerImageName = None, userVolumes = None, dataVolumes = None, resultsFolderPath = \"\", jobAlias = \"\"):\n",
    "    \"\"\"\n",
    "    Submits a shell command for execution (as an asynchronous job) inside a Docker compute domain.\n",
    "    :param shellCommand: shell command (string) defined by the user.\n",
    "    :param dockerComputeDomain: object (dictionary) that defines a Docker compute domain. A list of these kind of objects available to the user is returned by the function Jobs.getDockerComputeDomains().\n",
    "    :param dockerImageName: name (string) of the Docker image for executing the notebook. E.g.,  dockerImageName=\"Python (astro)\". An array of available Docker images is defined as the 'images' property in the dockerComputeDomain object.\n",
    "    :param userVolumes: a list with the names of user volumes (with optional write permissions) that will be mounted to the docker Image.\n",
    "           E.g., userVolumes = [{'name':'persistent', 'needsWriteAccess':False},{'name':'scratch', , 'needsWriteAccess':True}]\n",
    "           A list of available user volumes can be found as the 'userVolumes' property in the dockerComputeDomain object. If userVolumes=None, then all available user volumes are mounted, with 'needsWriteAccess' = True if the user has Write permissions on the volume.\n",
    "    :param dataVolumes: a list with the names of data volumes that will be mounted to the docker Image.\n",
    "           E.g., dataVolumes=[{\"name\":\"SDSS_DAS\"}, {\"name\":\"Recount\"}].\n",
    "           A list of available data volumes can be found as the 'volumes' property in the dockerComputeDomain object. If dataVolumes=None, then all available data volumes are mounted.\n",
    "    :param resultsFolderPath: full path to results folder (string) where the shell command is executed. E.g.: /home/idies/workspace/rootVolume/username/userVolume/jobsFolder. If not set, then a default folder will be set automatically.\n",
    "    :param jobAlias: alias (string) of job, defined by the user.\n",
    "    :return: the job ID (int)\n",
    "    :raises: Throws an exception if the HTTP request to the Authentication URL returns an error. Throws an exception if the HTTP request to the JOBM API returns an error, or if the volumes defined by the user are not available in the Docker compute domain.\n",
    "    :example: dockerComputeDomain = Jobs.getDockerComputeDomains()[0]; job = Jobs.submitShellCommandJob('pwd', dockerComputeDomain, 'Python (astro)', [{'name':'persistent'},{'name':'scratch', 'needsWriteAccess':True}], [{'name':'SDSS_DAS'}], 'myNewJob')\n",
    "    .. seealso:: Jobs.submitNotebookJob, Jobs.getJobStatus, Jobs.getDockerComputeDomains, Jobs.cancelJob\n",
    "    \"\"\"\n",
    "\n",
    "    token = Authentication.login(UserName=\"------\", Password=\"------\")\n",
    "    if token is not None and token != \"\":\n",
    "\n",
    "        if Config.isSciServerComputeEnvironment():\n",
    "            taskName = \"Compute.SciScript-Python.Jobs.submitShellCommandJob\"\n",
    "        else:\n",
    "            taskName = \"SciScript-Python.Jobs.submitShellCommandJob\"\n",
    "\n",
    "        if dockerComputeDomain is None:\n",
    "            dockerComputeDomains = getDockerComputeDomains();\n",
    "            if dockerComputeDomains .__len__() > 0:\n",
    "                dockerComputeDomain = dockerComputeDomains[0];\n",
    "            else:\n",
    "                raise Exception(\"There are no dockerComputeDomains available for the user.\");\n",
    "\n",
    "        if dockerImageName is None:\n",
    "            images = dockerComputeDomain.get('images');\n",
    "            if images.__len__() > 0:\n",
    "                dockerImageName = images[0].get('name')\n",
    "            else:\n",
    "                raise Exception(\"dockerComputeDomain has no docker images available for the user.\");\n",
    "\n",
    "        uVols = [];\n",
    "        for uVol in userVolumes:\n",
    "            found = False;\n",
    "            for vol in dockerComputeDomain.get('userVolumes'):\n",
    "                if vol.get('name') == uVol.get('name'):\n",
    "                    found = True;\n",
    "                    if (uVol.get('needsWriteAccess')):\n",
    "                        if uVol.get('needsWriteAccess') == True and 'write' in vol.get('allowedActions'):\n",
    "                            uVols.append({'userVolumeId': vol.get('id'), 'needsWriteAccess': True});\n",
    "                        else:\n",
    "                            uVols.append({'userVolumeId': vol.get('id'), 'needsWriteAccess': False});\n",
    "                    else:\n",
    "                        if 'write' in vol.get('allowedActions'):\n",
    "                            uVols.append({'userVolumeId': vol.get('id'), 'needsWriteAccess': True});\n",
    "                        else:\n",
    "                            uVols.append({'userVolumeId': vol.get('id'), 'needsWriteAccess': False});\n",
    "\n",
    "            if not found:\n",
    "                raise Exception(\"User volume '\" + uVol.get('name') + \"' not found within Compute domain\")\n",
    "\n",
    "        datVols = [];\n",
    "        for dVol in dataVolumes:\n",
    "            found = False;\n",
    "            for vol in dockerComputeDomain.get('volumes'):\n",
    "                name=dVol.get('name')\n",
    "                print(name)\n",
    "                if name == vol.get('name'):\n",
    "                    found = True\n",
    "                    if (vol.get('needsWriteAccess')):\n",
    "                        print(vol.get('needsWriteAccess'))\n",
    "                        print(vol.get('writable'))\n",
    "                        if vol.get('needsWriteAccess') == True and vol.get('writable') == True:\n",
    "                            datVols.append({'name': name, 'writable': True});\n",
    "                        else:\n",
    "                            datVols.append({'name': name, 'writable': False});\n",
    "                    else:\n",
    "                        if vol.get('writable'):\n",
    "                            datVols.append({'name': name, 'writable': True});\n",
    "                        else:\n",
    "                            datVols.append({'name': name, 'writable': False});\n",
    "                    found = True;\n",
    "\n",
    "            if not found:\n",
    "                raise Exception(\"Data volume '\" + dVol.get('name') + \"' not found within Compute domain\")\n",
    "\n",
    "\n",
    "        dockerComputeEndpoint = dockerComputeDomain.get('apiEndpoint');\n",
    "\n",
    "        dockerJobModel = {\n",
    "            \"command\": shellCommand,\n",
    "            \"submitterDID\": jobAlias,\n",
    "            \"dockerComputeEndpoint\": dockerComputeEndpoint,\n",
    "            \"dockerImageName\": dockerImageName,\n",
    "            \"volumeContainers\": datVols,\n",
    "            \"userVolumes\": uVols,\n",
    "            \"resultsFolderURI\": resultsFolderPath\n",
    "        }\n",
    "        data = json.dumps(dockerJobModel).encode()\n",
    "        url = Config.RacmApiURL + \"/jobm/rest/jobs/docker?TaskName=\"+taskName;\n",
    "        headers = {'X-Auth-Token': token, \"Content-Type\": \"application/json\"}\n",
    "        res = requests.post(url, data=data, headers=headers, stream=True)\n",
    "\n",
    "        if res.status_code != 200:\n",
    "            raise Exception(\"Error when submitting a job to the JOBM API.\\nHttp Response from JOBM API returned status code \" + str(res.status_code) + \":\\n\" + res.content.decode());\n",
    "        else:\n",
    "            return (json.loads(res.content.decode())).get('id')\n",
    "    else:\n",
    "        raise Exception(\"User token is not defined. First log into SciServer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sciserver User Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your sciserver username and password\n",
    "USERNAME='------'\n",
    "PASSWORD='------'\n",
    "\n",
    "# define the required job environment\n",
    "DOMAIN='COVID-19 Jobs'  # change with name of new compute domain\n",
    "IMAGE='SciServer Essentials'\n",
    "\n",
    "# define lists of user and data volumes that should be mounted\n",
    "# Add those that you \n",
    "USERVOLUMES=['Storage/'+USERNAME+'/persistent','Temporary/'+USERNAME+'/scratch']\n",
    "DATAVOLUMES=['COVID-19']\n",
    "\n",
    "RESULTSFOLDERPATH = \"/home/idies/workspace/covid19/code/ncov/interactive_notebooks/jobs\"\n",
    "JOBALIAS = \"covnorm-even_strand\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains=Jobs.getDockerComputeDomains()\n",
    "domain=None\n",
    "image=None\n",
    "volumes=[]\n",
    "userVolumes=[]\n",
    "dataVolumes=[]\n",
    "for d in domains:\n",
    "    if d['name'] == DOMAIN:\n",
    "        domain=d\n",
    "        for im in d['images']:\n",
    "            if im['name'] == IMAGE:\n",
    "                image = im\n",
    "        for v in d['volumes']:\n",
    "            if v['name'] in DATAVOLUMES:\n",
    "                dataVolumes.append({\"name\":v['name'],'needsWriteAccess':True})\n",
    "        for uv in d['userVolumes']:\n",
    "            path=pathForUserVolume(uv)\n",
    "            if path in USERVOLUMES:\n",
    "                userVolumes.append({'name':uv['name'],'rootVolumeName':uv['rootVolumeName']\n",
    "                                    ,'owner':uv['owner'],'needsWriteAccess':True})\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4: Draft Consensus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert any command line arguements needed for scipt.  If more than 1 arguement is needed, you will have to modify the CMD variable below with extra arguements.  My example is providing a path where you want analysis results stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nanopolish script..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "script='bash -x /home/idies/workspace/Temporary/'+USERNAME+'/scratch/CoverageNormalization/normalization.sh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Directory to process..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='/home/idies/workspace/covid19/sequencing_runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find samples for the analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_3_get_files(input_dir):\n",
    "\n",
    "    files=[]\n",
    "\n",
    "    for dirName, subdirList, fileList in walk(output_dir):\n",
    "        for i, d in enumerate(subdirList):\n",
    "            if(isdir(dirName+'/'+d+'/3-normalization')):\n",
    "                run_path = '%s/%s/artic-pipeline/2-length-filter/' % (base_dir, d)\n",
    "                for file in listdir(run_path):\n",
    "                    if file.endswith(\".fastq\"):\n",
    "                        files.append(join(run_path,file))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir='/home/idies/workspace/Temporary/'+USERNAME+'/scratch/CoverageNormalization'\n",
    "module_3_input_files=module_3_get_files(output_dir)\n",
    "if len(module_3_input_files)==0:\n",
    "    print(\"Input Fastq files for Module 3 not found!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(module_3_input_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create command: merge bash script with parameters and input files for analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands=[]\n",
    "for i in range(len(module_3_input_files)):\n",
    "    module_3_job_no=i\n",
    "    command = script + \" \" + module_3_input_files[i] \" \" + output_dir + \" \" + str(module_3_job_no)\n",
    "    commands.append(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bash -x /home/idies/workspace/Temporary/'+USERNAME+'/scratch/CoverageNormalization/normalization.sh /home/idies/workspace/covid19/sequencing_runs/20200405_0422_GA30000_FAN30842_00fb1614/artic-pipeline/2-length-filter/NTC_NB12.fastq 0'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submit All Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_batch(commands):\n",
    "    jobs=[]\n",
    "    for command in commands:\n",
    "        job=Jobs.submitShellCommandJob(shellCommand=command\n",
    "                                    , dockerComputeDomain = domain\n",
    "                                    , dockerImageName = IMAGE\n",
    "                                    , userVolumes = userVolumes, dataVolumes=dataVolumes\n",
    "                                    , resultsFolderPath = \"/home/idies/workspace/Temporary/'+USERNAME+'/scratch/jobs\"\n",
    "                                    , jobAlias = JOBALIAS)\n",
    "        jobs.append(job)\n",
    "        time.sleep(30)\n",
    "    return jobs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-17d623c7e386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubmit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-74e838fd732a>\u001b[0m in \u001b[0;36msubmit_batch\u001b[0;34m(commands)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                     , jobAlias = JOBALIAS)\n\u001b[1;32m     10\u001b[0m         \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "jobs=submit_batch(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submit Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64858\n"
     ]
    }
   ],
   "source": [
    "command=commands[0]\n",
    "job=Jobs.submitShellCommandJob(shellCommand=command\n",
    "                            , dockerComputeDomain = domain\n",
    "                            , dockerImageName = IMAGE\n",
    "                            , userVolumes = userVolumes, dataVolumes=dataVolumes\n",
    "                            , resultsFolderPath = \"/home/idies/workspace/Temporary/'+USERNAME+'/scratch/jobs\"\n",
    "                            , jobAlias = JOBALIAS)\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 32, 'statusMeaning': 'SUCCESS', 'jobId': 64858}\n"
     ]
    }
   ],
   "source": [
    "print(Jobs.getJobStatus(64858))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cancel single job\n",
    "Jobs.cancelJob(64479)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cancel batch jobs\n",
    "#for job in jobs:\n",
    "#    Jobs.cancelJob(job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
